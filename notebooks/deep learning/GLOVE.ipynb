{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout, Attention\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "def load_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df['Review'] = df['Review'].astype(str).fillna('')\n",
        "\n",
        "    print(\"Validating 'Rating' column...\")\n",
        "    invalid_rows = df[~df['Rating'].apply(lambda x: isinstance(x, (int, float)) and 1 <= x <= 5)]\n",
        "    if not invalid_rows.empty:\n",
        "        print(f\"Found {len(invalid_rows)} invalid ratings:\")\n",
        "        print(invalid_rows[['Review', 'Rating']].head())\n",
        "        print(\"Removing rows with invalid ratings...\")\n",
        "        df = df[df['Rating'].apply(lambda x: isinstance(x, (int, float)) and 1 <= x <= 5)]\n",
        "\n",
        "    reviews = df['Review'].values\n",
        "    ratings = df['Rating'].astype(int).values - 1\n",
        "\n",
        "    review_lengths = [len(review.split()) for review in reviews]\n",
        "    print(f\"Average review length: {np.mean(review_lengths):.1f}, Max length: {np.max(review_lengths)}\")\n",
        "    print(f\"Loaded {len(reviews)} valid reviews with ratings.\")\n",
        "    return reviews, ratings\n",
        "\n",
        "# Download and extract GloVe embeddings\n",
        "def download_glove():\n",
        "    if not os.path.exists(GLOVE_DIR):\n",
        "        os.makedirs(GLOVE_DIR)\n",
        "    if not os.path.exists(GLOVE_FILE):\n",
        "        print(\"Downloading GloVe embeddings...\")\n",
        "        urllib.request.urlretrieve(GLOVE_URL, 'glove.6B.zip')\n",
        "        with zipfile.ZipFile('glove.6B.zip', 'r') as zip_ref:\n",
        "            zip_ref.extractall(GLOVE_DIR)\n",
        "        os.remove('glove.6B.zip')\n",
        "        print(\"GloVe embeddings downloaded and extracted.\")\n",
        "\n",
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings():\n",
        "    download_glove()\n",
        "    embeddings_index = {}\n",
        "    with open(GLOVE_FILE, encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    return embeddings_index\n",
        "\n",
        "# Create embedding matrix\n",
        "def create_embedding_matrix(tokenizer, embeddings_index):\n",
        "    word_index = tokenizer.word_index\n",
        "    embedding_matrix = np.zeros((MAX_WORDS, EMBEDDING_DIM))\n",
        "    for word, i in word_index.items():\n",
        "        if i < MAX_WORDS:\n",
        "            embedding_vector = embeddings_index.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix\n",
        "\n",
        "# Preprocess text data\n",
        "def preprocess_data(reviews, ratings):\n",
        "    tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
        "    tokenizer.fit_on_texts(reviews)\n",
        "    sequences = tokenizer.texts_to_sequences(reviews)\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=MAX_LEN, padding='post')\n",
        "\n",
        "    print(\"Converting ratings to one-hot encoded format...\")\n",
        "    labels = to_categorical(ratings, num_classes=5)\n",
        "    return padded_sequences, labels, tokenizer\n",
        "\n",
        "# Build BiLSTM model with attention\n",
        "def build_model(embedding_matrix):\n",
        "    inputs = Input(shape=(MAX_LEN,))\n",
        "    embedding = Embedding(input_dim=MAX_WORDS, output_dim=EMBEDDING_DIM,\n",
        "                         weights=[embedding_matrix], input_length=MAX_LEN, trainable=False)(inputs)\n",
        "    bilstm1 = Bidirectional(LSTM(128, return_sequences=True))(embedding)\n",
        "    bilstm2 = Bidirectional(LSTM(64, return_sequences=True))(bilstm1)\n",
        "    attention = Attention()([bilstm2, bilstm2])\n",
        "    pooled = tf.keras.layers.GlobalAveragePooling1D()(attention)\n",
        "    dense = Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(pooled)\n",
        "    dropout = Dropout(0.5)(dense)\n",
        "    outputs = Dense(5, activation='softmax')(dropout)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "vXhtLPb6D4P-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "def main():\n",
        "    file_path = 'balanced_data_for_DL.csv'  # Update with your file path\n",
        "    reviews, ratings = load_data(file_path)\n",
        "\n",
        "    if len(reviews) == 0:\n",
        "        raise ValueError(\"No valid data remains after cleaning. Please check 'Rating' column for invalid values.\")\n",
        "\n",
        "    print(\"Computing class weights...\")\n",
        "    class_weights = compute_class_weight('balanced', classes=np.arange(5), y=ratings)\n",
        "    class_weights = dict(enumerate(class_weights))\n",
        "    print(\"Class weights:\", class_weights)\n",
        "\n",
        "    padded_sequences, labels, tokenizer = preprocess_data(reviews, ratings)\n",
        "\n",
        "    embeddings_index = load_glove_embeddings()\n",
        "    embedding_matrix = create_embedding_matrix(tokenizer, embeddings_index)\n",
        "\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "        padded_sequences, labels, test_size=0.2, random_state=42\n",
        "    )\n",
        "    X_val, X_test, y_val, y_test = train_test_split(\n",
        "        X_temp, y_temp, test_size=0.5, random_state=42\n",
        "    )\n",
        "\n",
        "    model = build_model(embedding_matrix)\n",
        "    model.build(input_shape=(None, MAX_LEN))\n",
        "    model.summary()\n",
        "\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=5, restore_best_weights=True\n",
        "    )\n",
        "    lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=20,\n",
        "        batch_size=32,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=[early_stopping, lr_scheduler],\n",
        "        class_weight=class_weights,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"\\nTest Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_test_classes = np.argmax(y_test, axis=1)\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_test_classes, y_pred_classes))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wluB01F3D4Xf",
        "outputId": "d0ab0812-f354-4fb6-ac2b-8727a722a097"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating 'Rating' column...\n",
            "Average review length: 74.5, Max length: 4815\n",
            "Loaded 115000 valid reviews with ratings.\n",
            "Computing class weights...\n",
            "Class weights: {0: np.float64(1.0), 1: np.float64(1.0), 2: np.float64(1.0), 3: np.float64(1.0), 4: np.float64(1.0)}\n",
            "Converting ratings to one-hot encoded format...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │  \u001b[38;5;34m1,000,000\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │    \u001b[38;5;34m234,496\u001b[0m │ embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m164,352\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m325\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">234,496</span> │ embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,407,429\u001b[0m (5.37 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,407,429</span> (5.37 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m407,429\u001b[0m (1.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,429</span> (1.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,000,000\u001b[0m (3.81 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> (3.81 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 22ms/step - accuracy: 0.3121 - loss: 1.9581 - val_accuracy: 0.4110 - val_loss: 1.4141 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 22ms/step - accuracy: 0.4127 - loss: 1.4004 - val_accuracy: 0.4360 - val_loss: 1.3104 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 21ms/step - accuracy: 0.4294 - loss: 1.3233 - val_accuracy: 0.4428 - val_loss: 1.2806 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 22ms/step - accuracy: 0.4494 - loss: 1.2765 - val_accuracy: 0.4650 - val_loss: 1.2341 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 21ms/step - accuracy: 0.4582 - loss: 1.2501 - val_accuracy: 0.4610 - val_loss: 1.2354 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 22ms/step - accuracy: 0.4681 - loss: 1.2275 - val_accuracy: 0.4759 - val_loss: 1.2111 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 22ms/step - accuracy: 0.4768 - loss: 1.2083 - val_accuracy: 0.4737 - val_loss: 1.2070 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.4852 - loss: 1.1913 - val_accuracy: 0.4836 - val_loss: 1.1897 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 21ms/step - accuracy: 0.4936 - loss: 1.1752 - val_accuracy: 0.4926 - val_loss: 1.1743 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.4987 - loss: 1.1634 - val_accuracy: 0.4881 - val_loss: 1.1677 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 21ms/step - accuracy: 0.5022 - loss: 1.1509 - val_accuracy: 0.4925 - val_loss: 1.1605 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 22ms/step - accuracy: 0.5065 - loss: 1.1367 - val_accuracy: 0.4949 - val_loss: 1.1585 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 21ms/step - accuracy: 0.5128 - loss: 1.1206 - val_accuracy: 0.4923 - val_loss: 1.1601 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 21ms/step - accuracy: 0.5171 - loss: 1.1138 - val_accuracy: 0.4974 - val_loss: 1.1518 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 21ms/step - accuracy: 0.5211 - loss: 1.1043 - val_accuracy: 0.5017 - val_loss: 1.1463 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 21ms/step - accuracy: 0.5298 - loss: 1.0903 - val_accuracy: 0.5031 - val_loss: 1.1516 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 22ms/step - accuracy: 0.5326 - loss: 1.0836 - val_accuracy: 0.4997 - val_loss: 1.1489 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 21ms/step - accuracy: 0.5447 - loss: 1.0584 - val_accuracy: 0.5076 - val_loss: 1.1476 - learning_rate: 5.0000e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 22ms/step - accuracy: 0.5514 - loss: 1.0406 - val_accuracy: 0.5022 - val_loss: 1.1524 - learning_rate: 5.0000e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m2875/2875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 22ms/step - accuracy: 0.5607 - loss: 1.0210 - val_accuracy: 0.5063 - val_loss: 1.1495 - learning_rate: 2.5000e-05\n",
            "\n",
            "Test Accuracy: 0.5097, Test Loss: 1.1440\n",
            "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1400  510  213   49   55]\n",
            " [ 525  837  765  149   70]\n",
            " [ 221  463 1075  429  132]\n",
            " [  74   94  567  908  603]\n",
            " [  49   59  167  445 1641]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AeayBUTcD4cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1EhRkKFnD4fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "efWkQOI0D4jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GzXLCv8hD4ml"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}